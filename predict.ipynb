{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dacbbab3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "ERROR: To modify pip, please run the following command:\n",
      "C:\\Users\\omkar\\AppData\\Local\\Programs\\Python\\Python310\\python.exe -m pip install -q --upgrade pip\n",
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Model loaded: best_model1.h5\n",
      "Model input shape: (None, 168, 8)\n",
      "âœ… Loaded existing scalers.\n",
      "ğŸ—“ï¸ Mondays to evaluate: [Timestamp('2025-01-06 12:00:00'), Timestamp('2025-01-13 12:00:00'), Timestamp('2025-01-20 12:00:00'), Timestamp('2025-01-27 12:00:00'), Timestamp('2025-02-03 12:00:00'), Timestamp('2025-02-10 12:00:00'), Timestamp('2025-02-17 12:00:00'), Timestamp('2025-02-24 12:00:00'), Timestamp('2025-03-03 12:00:00'), Timestamp('2025-03-10 12:00:00'), Timestamp('2025-03-17 12:00:00'), Timestamp('2025-03-24 12:00:00'), Timestamp('2025-03-31 12:00:00'), Timestamp('2025-04-07 12:00:00'), Timestamp('2025-04-14 12:00:00'), Timestamp('2025-04-21 12:00:00'), Timestamp('2025-04-28 12:00:00')]\n",
      "âœ… 2025-01-06 12:00:00 done | actual: {'temperature_2m': 28.9, 'relativehumidity_2m': 31.0, 'pressure_msl': 1013.3} | pred: {'temperature_2m': 29.876087188720703, 'relativehumidity_2m': 26.93418312072754, 'pressure_msl': 1012.0742797851562}\n",
      "âœ… 2025-01-13 12:00:00 done | actual: {'temperature_2m': 27.8, 'relativehumidity_2m': 45.0, 'pressure_msl': 1014.0} | pred: {'temperature_2m': 29.013010025024414, 'relativehumidity_2m': 37.3906135559082, 'pressure_msl': 1012.8837890625}\n",
      "âœ… 2025-01-20 12:00:00 done | actual: {'temperature_2m': 29.1, 'relativehumidity_2m': 30.0, 'pressure_msl': 1014.6} | pred: {'temperature_2m': 30.136213302612305, 'relativehumidity_2m': 26.760120391845703, 'pressure_msl': 1013.2630615234375}\n",
      "âœ… 2025-01-27 12:00:00 done | actual: {'temperature_2m': 31.9, 'relativehumidity_2m': 23.0, 'pressure_msl': 1011.9} | pred: {'temperature_2m': 32.83841323852539, 'relativehumidity_2m': 20.63652992248535, 'pressure_msl': 1010.7515258789062}\n",
      "âœ… 2025-02-03 12:00:00 done | actual: {'temperature_2m': 32.9, 'relativehumidity_2m': 24.0, 'pressure_msl': 1012.6} | pred: {'temperature_2m': 34.02657699584961, 'relativehumidity_2m': 20.642663955688477, 'pressure_msl': 1011.2864379882812}\n",
      "âœ… 2025-02-10 12:00:00 done | actual: {'temperature_2m': 32.8, 'relativehumidity_2m': 27.0, 'pressure_msl': 1014.4} | pred: {'temperature_2m': 33.582740783691406, 'relativehumidity_2m': 24.761796951293945, 'pressure_msl': 1013.134765625}\n",
      "âœ… 2025-02-17 12:00:00 done | actual: {'temperature_2m': 33.6, 'relativehumidity_2m': 13.0, 'pressure_msl': 1014.4} | pred: {'temperature_2m': 34.47698211669922, 'relativehumidity_2m': 13.246857643127441, 'pressure_msl': 1013.072021484375}\n",
      "âœ… 2025-02-24 12:00:00 done | actual: {'temperature_2m': 33.0, 'relativehumidity_2m': 16.0, 'pressure_msl': 1016.2} | pred: {'temperature_2m': 33.77983856201172, 'relativehumidity_2m': 15.02242374420166, 'pressure_msl': 1014.5423583984375}\n",
      "âœ… 2025-03-03 12:00:00 done | actual: {'temperature_2m': 35.2, 'relativehumidity_2m': 16.0, 'pressure_msl': 1012.3} | pred: {'temperature_2m': 35.79056167602539, 'relativehumidity_2m': 15.098221778869629, 'pressure_msl': 1011.1543579101562}\n",
      "âœ… 2025-03-10 12:00:00 done | actual: {'temperature_2m': 35.6, 'relativehumidity_2m': 20.0, 'pressure_msl': 1012.8} | pred: {'temperature_2m': 36.17216110229492, 'relativehumidity_2m': 17.46300506591797, 'pressure_msl': 1011.5507202148438}\n",
      "âœ… 2025-03-17 12:00:00 done | actual: {'temperature_2m': 35.5, 'relativehumidity_2m': 16.0, 'pressure_msl': 1012.4} | pred: {'temperature_2m': 36.146915435791016, 'relativehumidity_2m': 14.87644100189209, 'pressure_msl': 1011.1964111328125}\n",
      "âœ… 2025-03-24 12:00:00 done | actual: {'temperature_2m': 35.9, 'relativehumidity_2m': 14.0, 'pressure_msl': 1012.9} | pred: {'temperature_2m': 36.46381759643555, 'relativehumidity_2m': 13.19387435913086, 'pressure_msl': 1011.6300048828125}\n",
      "âœ… 2025-03-31 12:00:00 done | actual: {'temperature_2m': 38.5, 'relativehumidity_2m': 17.0, 'pressure_msl': 1008.7} | pred: {'temperature_2m': 38.45456314086914, 'relativehumidity_2m': 14.544774055480957, 'pressure_msl': 1007.8861083984375}\n",
      "âœ… 2025-04-07 12:00:00 done | actual: {'temperature_2m': 38.5, 'relativehumidity_2m': 11.0, 'pressure_msl': 1010.2} | pred: {'temperature_2m': 38.58512878417969, 'relativehumidity_2m': 10.58621883392334, 'pressure_msl': 1009.2738647460938}\n",
      "âœ… 2025-04-14 12:00:00 done | actual: {'temperature_2m': 38.7, 'relativehumidity_2m': 10.0, 'pressure_msl': 1009.0} | pred: {'temperature_2m': 38.7023811340332, 'relativehumidity_2m': 10.618098258972168, 'pressure_msl': 1008.2022705078125}\n",
      "âœ… 2025-04-21 12:00:00 done | actual: {'temperature_2m': 37.9, 'relativehumidity_2m': 17.0, 'pressure_msl': 1010.1} | pred: {'temperature_2m': 38.11484909057617, 'relativehumidity_2m': 15.71690559387207, 'pressure_msl': 1009.223876953125}\n",
      "âœ… 2025-04-28 12:00:00 done | actual: {'temperature_2m': 38.8, 'relativehumidity_2m': 12.0, 'pressure_msl': 1007.7} | pred: {'temperature_2m': 39.19034957885742, 'relativehumidity_2m': 11.008116722106934, 'pressure_msl': 1007.1141357421875}\n",
      "\n",
      "ğŸ“ Detailed results saved: monday_predictions_detailed.csv\n",
      "ğŸ“ˆ Summary saved: monday_predictions_summary.csv\n",
      "\n",
      "Summary:\n",
      "          parameter  mean_error  mean_percent_error\n",
      "       pressure_msl   -1.132942           -0.111875\n",
      "relativehumidity_2m   -1.970539           -8.031069\n",
      "     temperature_2m    0.632388            1.963954\n"
     ]
    }
   ],
   "source": [
    "# ===========================================================\n",
    "# ğŸ“¦ Clean install compatible dependencies\n",
    "# ===========================================================\n",
    "!pip install -q --upgrade pip\n",
    "!pip install -q \"tensorflow==2.19.0\" \"pandas==2.2.2\" \"numpy<2.1\" \"scikit-learn==1.5.1\" requests joblib\n",
    "\n",
    "# ===========================================================\n",
    "# ğŸŒ¤ï¸ Predict Mondays (Janâ€“Apr 2025) â€” Plantera Edition\n",
    "# ===========================================================\n",
    "import os, math, requests, joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "\n",
    "# --------- USER CONFIG ----------\n",
    "MODEL_PATH = \"best_model1.h5\"        # your uploaded model file (.h5)\n",
    "SCALER_FEATURE_PATH = \"feature_scaler.save\"\n",
    "SCALER_TARGET_PATH = \"target_scaler.save\"\n",
    "\n",
    "LAT, LON = 18.5204, 73.8567         # Pune (change if needed)\n",
    "SEQ_LEN = 168                       # same as training (1 week)\n",
    "\n",
    "TARGETS = [\"temperature_2m\", \"relativehumidity_2m\", \"pressure_msl\"]\n",
    "FEATURES_CORE = [\"temperature_2m\", \"relativehumidity_2m\", \"pressure_msl\", \"precipitation\"]\n",
    "INPUT_TIME_FEATS = [\"hour_sin\", \"hour_cos\", \"day_sin\", \"day_cos\"]\n",
    "INPUT_FEATURES = FEATURES_CORE + INPUT_TIME_FEATS\n",
    "\n",
    "TRAIN_SCALER_REF_START = \"2024-01-01\"\n",
    "TRAIN_SCALER_REF_END   = \"2024-12-31\"\n",
    "\n",
    "OUT_DETAILED_CSV = \"monday_predictions_detailed.csv\"\n",
    "OUT_SUMMARY_CSV = \"monday_predictions_summary.csv\"\n",
    "# --------------------------------\n",
    "\n",
    "# âœ… Check model file\n",
    "if not os.path.exists(MODEL_PATH):\n",
    "    raise FileNotFoundError(f\"Upload {MODEL_PATH} to your Colab session before running!\")\n",
    "\n",
    "# âœ… Load model (with MSE custom)\n",
    "model = load_model(MODEL_PATH, custom_objects={\n",
    "    \"mse\": MeanSquaredError(),\n",
    "    \"MeanSquaredError\": MeanSquaredError()\n",
    "})\n",
    "print(\"âœ… Model loaded:\", MODEL_PATH)\n",
    "print(\"Model input shape:\", model.input_shape)\n",
    "\n",
    "# ===========================================================\n",
    "# ğŸŒ Fetch historical weather data (Open-Meteo)\n",
    "# ===========================================================\n",
    "def fetch_open_meteo(start_date, end_date):\n",
    "    url = (\n",
    "        f\"https://archive-api.open-meteo.com/v1/archive?\"\n",
    "        f\"latitude={LAT}&longitude={LON}\"\n",
    "        f\"&start_date={start_date}&end_date={end_date}\"\n",
    "        f\"&hourly=temperature_2m,relativehumidity_2m,pressure_msl,precipitation\"\n",
    "        f\"&timezone=Asia/Kolkata\"\n",
    "    )\n",
    "    r = requests.get(url)\n",
    "    r.raise_for_status()\n",
    "    j = r.json()\n",
    "    if \"hourly\" not in j:\n",
    "        return pd.DataFrame()\n",
    "    df = pd.DataFrame(j[\"hourly\"])\n",
    "    df[\"time\"] = pd.to_datetime(df[\"time\"])\n",
    "    for c in FEATURES_CORE:\n",
    "        if c not in df.columns:\n",
    "            df[c] = 0.0\n",
    "    return df.rename(columns={\"time\": \"time\"})\n",
    "\n",
    "# ===========================================================\n",
    "# ğŸ§© Build or Load Scalers\n",
    "# ===========================================================\n",
    "def build_or_load_scalers():\n",
    "    if os.path.exists(SCALER_FEATURE_PATH) and os.path.exists(SCALER_TARGET_PATH):\n",
    "        feat_scaler = joblib.load(SCALER_FEATURE_PATH)\n",
    "        targ_scaler = joblib.load(SCALER_TARGET_PATH)\n",
    "        print(\"âœ… Loaded existing scalers.\")\n",
    "        return feat_scaler, targ_scaler\n",
    "\n",
    "    print(\"âš ï¸ Scalers not found â€” building from 2024 historical data...\")\n",
    "    ref_df = fetch_open_meteo(TRAIN_SCALER_REF_START, TRAIN_SCALER_REF_END)\n",
    "    if ref_df.empty:\n",
    "        raise RuntimeError(\"Failed to fetch reference data for scalers.\")\n",
    "    \n",
    "    ref_df[\"hour\"] = ref_df[\"time\"].dt.hour\n",
    "    ref_df[\"dayofyear\"] = ref_df[\"time\"].dt.dayofyear\n",
    "    ref_df[\"hour_sin\"] = np.sin(2*np.pi*ref_df[\"hour\"]/24)\n",
    "    ref_df[\"hour_cos\"] = np.cos(2*np.pi*ref_df[\"hour\"]/24)\n",
    "    ref_df[\"day_sin\"] = np.sin(2*np.pi*ref_df[\"dayofyear\"]/365)\n",
    "    ref_df[\"day_cos\"] = np.cos(2*np.pi*ref_df[\"dayofyear\"]/365)\n",
    "\n",
    "    feat_df = ref_df[INPUT_FEATURES].astype(float)\n",
    "    targ_df = ref_df[TARGETS].astype(float)\n",
    "\n",
    "    feat_scaler = MinMaxScaler().fit(feat_df)\n",
    "    targ_scaler = MinMaxScaler().fit(targ_df)\n",
    "\n",
    "    joblib.dump(feat_scaler, SCALER_FEATURE_PATH)\n",
    "    joblib.dump(targ_scaler, SCALER_TARGET_PATH)\n",
    "    print(\"âœ… Built and saved scalers.\")\n",
    "    return feat_scaler, targ_scaler\n",
    "\n",
    "feature_scaler, target_scaler = build_or_load_scalers()\n",
    "\n",
    "# ===========================================================\n",
    "# ğŸ•’ Prepare features with cyclical encoding\n",
    "# ===========================================================\n",
    "def make_input_features(df):\n",
    "    df = df.copy()\n",
    "    for c in FEATURES_CORE:\n",
    "        if c not in df.columns:\n",
    "            df[c] = 0.0\n",
    "    for c in FEATURES_CORE:\n",
    "        df[c] = pd.to_numeric(df[c], errors=\"coerce\").fillna(0.0)\n",
    "    df[\"hour\"] = df[\"time\"].dt.hour\n",
    "    df[\"dayofyear\"] = df[\"time\"].dt.dayofyear\n",
    "    df[\"hour_sin\"] = np.sin(2*np.pi*df[\"hour\"]/24)\n",
    "    df[\"hour_cos\"] = np.cos(2*np.pi*df[\"hour\"]/24)\n",
    "    df[\"day_sin\"] = np.sin(2*np.pi*df[\"dayofyear\"]/365)\n",
    "    df[\"day_cos\"] = np.cos(2*np.pi*df[\"dayofyear\"]/365)\n",
    "    return df[INPUT_FEATURES]\n",
    "\n",
    "# ===========================================================\n",
    "# ğŸ”® Predict for one timestamp\n",
    "# ===========================================================\n",
    "def predict_for_timestamp(ts: pd.Timestamp):\n",
    "    start_dt = (ts - pd.Timedelta(hours=SEQ_LEN)).date().strftime(\"%Y-%m-%d\")\n",
    "    end_dt = ts.date().strftime(\"%Y-%m-%d\")\n",
    "    df = fetch_open_meteo(start_dt, end_dt)\n",
    "    if df.empty:\n",
    "        print(f\"âš ï¸ No data for {ts.date()}\")\n",
    "        return None\n",
    "\n",
    "    df = df[(df[\"time\"] > ts - pd.Timedelta(hours=SEQ_LEN)) & (df[\"time\"] <= ts)]\n",
    "    if len(df) < SEQ_LEN:\n",
    "        print(f\"âš ï¸ Not enough hours for {ts} â€” have {len(df)}, need {SEQ_LEN}\")\n",
    "        return None\n",
    "\n",
    "    feat_df = make_input_features(df)\n",
    "    feat_scaled = feature_scaler.transform(feat_df)\n",
    "    X = feat_scaled.reshape(1, SEQ_LEN, feat_scaled.shape[1])\n",
    "\n",
    "    y_scaled = model.predict(X, verbose=0)\n",
    "    y_pred = target_scaler.inverse_transform(y_scaled)[0]\n",
    "\n",
    "    actual_row = df[df[\"time\"] == ts]\n",
    "    if actual_row.empty:\n",
    "        actual_row = df.iloc[[-1]]\n",
    "    actual_vals = [float(actual_row.iloc[0].get(t, np.nan)) for t in TARGETS]\n",
    "\n",
    "    return {\n",
    "        \"timestamp\": str(ts),\n",
    "        \"actual\": dict(zip(TARGETS, actual_vals)),\n",
    "        \"predicted\": dict(zip(TARGETS, [float(x) for x in y_pred]))\n",
    "    }\n",
    "\n",
    "# ===========================================================\n",
    "# ğŸ“† Mondays list (Janâ€“Apr 2025)\n",
    "# ===========================================================\n",
    "mondays = []\n",
    "for month in range(1, 5):\n",
    "    d = dt.date(2025, month, 1)\n",
    "    while d.month == month:\n",
    "        if d.weekday() == 0:  # Monday\n",
    "            mondays.append(pd.Timestamp(d.year, d.month, d.day, 12))\n",
    "        d += dt.timedelta(days=1)\n",
    "\n",
    "print(\"ğŸ—“ï¸ Mondays to evaluate:\", mondays)\n",
    "\n",
    "# ===========================================================\n",
    "# ğŸš€ Run predictions\n",
    "# ===========================================================\n",
    "detailed_rows = []\n",
    "for ts in mondays:\n",
    "    res = predict_for_timestamp(ts)\n",
    "    if res is None:\n",
    "        continue\n",
    "    for t in TARGETS:\n",
    "        actual = res[\"actual\"].get(t, np.nan)\n",
    "        pred = res[\"predicted\"].get(t, np.nan)\n",
    "        err = pred - actual if not math.isnan(actual) else np.nan\n",
    "        pct = (err / actual * 100) if (not math.isnan(actual) and actual != 0) else np.nan\n",
    "        detailed_rows.append({\n",
    "            \"timestamp\": res[\"timestamp\"],\n",
    "            \"parameter\": t,\n",
    "            \"actual\": actual,\n",
    "            \"predicted\": pred,\n",
    "            \"error\": err,\n",
    "            \"percent_error\": pct\n",
    "        })\n",
    "    print(f\"âœ… {ts} done | actual: {res['actual']} | pred: {res['predicted']}\")\n",
    "\n",
    "# ===========================================================\n",
    "# ğŸ“Š Save results\n",
    "# ===========================================================\n",
    "if detailed_rows:\n",
    "    df_details = pd.DataFrame(detailed_rows)\n",
    "    df_details.to_csv(OUT_DETAILED_CSV, index=False)\n",
    "    summary = (\n",
    "        df_details.groupby(\"parameter\")\n",
    "        .agg({\"error\": \"mean\", \"percent_error\": \"mean\"})\n",
    "        .reset_index()\n",
    "        .rename(columns={\"error\": \"mean_error\", \"percent_error\": \"mean_percent_error\"})\n",
    "    )\n",
    "    summary.to_csv(OUT_SUMMARY_CSV, index=False)\n",
    "    print(\"\\nğŸ“ Detailed results saved:\", OUT_DETAILED_CSV)\n",
    "    print(\"ğŸ“ˆ Summary saved:\", OUT_SUMMARY_CSV)\n",
    "    print(\"\\nSummary:\")\n",
    "    print(summary.to_string(index=False))\n",
    "else:\n",
    "    print(\"âš ï¸ No predictions generated.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
